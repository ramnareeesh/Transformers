{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAVWjKkL5SpPjKaUkBoQbC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"id":"Tv1KZQQ90238","executionInfo":{"status":"ok","timestamp":1730021899363,"user_tz":-330,"elapsed":498,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as f"]},{"cell_type":"code","source":["with open('paragraphs.txt' , 'r' , encoding='utf-8') as f:\n","    text = f.read()"],"metadata":{"id":"5YO0gTXi6PJu","executionInfo":{"status":"ok","timestamp":1730021111999,"user_tz":-330,"elapsed":9,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(\"length : \",len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tai8en6v6crr","executionInfo":{"status":"ok","timestamp":1730021111999,"user_tz":-330,"elapsed":8,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"e1791c6f-afc9-4c77-bcd4-66b28b9604c6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["length :  8229768\n"]}]},{"cell_type":"code","source":["print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49WSy4fZV8AY","executionInfo":{"status":"ok","timestamp":1730021111999,"user_tz":-330,"elapsed":6,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"664742b4-a5fd-4282-ebea-9509db08f662"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["This biographical article related to French artistic gymnastics is a stub. You can help Wikipedia by expanding it.\n","InsideAR was the largest Augmented Reality event in Europe. It was organized and supported by metaio GmbH every year. The first event was held in 2010, had since expanded globally and was run at multiple locations around the world.  However, after Apple purchased metaio in May 2015, metaio cancelled the InsideAR conference 2015 without any statements about the conference's future. \n","The Fearing Mind is an American horror television series that aired on the Fox Family Channel from October 21 until December 2, 2000. \n","Bill Fearing, a famous writer of suspense thrillers, gets his ideas from things that happen in his family. When he gets an idea, the viewers enter his mind and see the gruesome events unfold. \n","It had a bronze barrel and lacked a modern recoil system, using only an ineffective spring-mounted spade brake, and was virtually obsolescent on its introduction. Nonethele\n"]}]},{"cell_type":"code","source":["chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgRuAWh4WM5f","executionInfo":{"status":"ok","timestamp":1730021111999,"user_tz":-330,"elapsed":4,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"e1dc16e5-5976-41eb-f69b-1596ed25a0d3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_abcdefghijklmnopqrstuvwxyz{}\n","93\n"]}]},{"cell_type":"code","source":["stringToNumbers = {ch:i for i,ch in enumerate(chars)}\n","numbersToString = {i:ch for i,ch in enumerate(chars)}\n","encode = lambda s: [stringToNumbers[c] for c in s]\n","decode = lambda l: ''.join([numbersToString[i] for i in l])\n","\n","print(encode(\"hey there , how are you\"))\n","print(decode(encode(\"hey there , how are you\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3mgVobwZPwG","executionInfo":{"status":"ok","timestamp":1730021114055,"user_tz":-330,"elapsed":3,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"0ccf9e4e-0698-4642-b853-7ab500ced80f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[72, 69, 89, 1, 84, 72, 69, 82, 69, 1, 13, 1, 72, 79, 87, 1, 65, 82, 69, 1, 89, 79, 85]\n","hey there , how are you\n"]}]},{"cell_type":"code","source":["data=torch.tensor(encode(text),dtype=torch.long)\n","print(data[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xQKzPhLFol_","executionInfo":{"status":"ok","timestamp":1730021117012,"user_tz":-330,"elapsed":1704,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"264970bc-a871-47ae-8e58-fa40f77affd7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([53, 72, 73, 83,  1, 66, 73, 79, 71, 82, 65, 80, 72, 73, 67, 65, 76,  1,\n","        65, 82, 84, 73, 67, 76, 69,  1, 82, 69, 76, 65, 84, 69, 68,  1, 84, 79,\n","         1, 39, 82, 69, 78, 67, 72,  1, 65, 82, 84, 73, 83, 84, 73, 67,  1, 71,\n","        89, 77, 78, 65, 83, 84, 73, 67, 83,  1, 73, 83,  1, 65,  1, 83, 84, 85,\n","        66, 15,  1, 58, 79, 85,  1, 67, 65, 78,  1, 72, 69, 76, 80,  1, 56, 73,\n","        75, 73, 80, 69, 68, 73, 65,  1, 66, 89,  1, 69, 88, 80, 65, 78, 68, 73,\n","        78, 71,  1, 73, 84, 15,  0, 42, 78, 83, 73, 68, 69, 34, 51,  1, 87, 65,\n","        83,  1, 84, 72, 69,  1, 76, 65, 82, 71, 69, 83, 84,  1, 34, 85, 71, 77,\n","        69, 78, 84, 69, 68,  1, 51, 69, 65, 76, 73, 84, 89,  1, 69, 86, 69, 78,\n","        84,  1, 73, 78,  1, 38, 85, 82, 79, 80, 69, 15,  1, 42, 84,  1, 87, 65,\n","        83,  1, 79, 82, 71, 65, 78, 73, 90, 69, 68,  1, 65, 78, 68,  1, 83, 85,\n","        80, 80, 79, 82, 84, 69, 68,  1, 66, 89,  1, 77, 69, 84, 65, 73, 79,  1,\n","        40, 77, 66, 41,  1, 69, 86, 69, 82, 89,  1, 89, 69, 65, 82, 15,  1, 53,\n","        72, 69,  1, 70, 73, 82, 83, 84,  1, 69, 86, 69, 78, 84,  1, 87, 65, 83,\n","         1, 72, 69, 76, 68,  1, 73, 78,  1, 19, 17, 18, 17, 13,  1, 72, 65, 68,\n","         1, 83, 73, 78, 67, 69,  1, 69, 88, 80, 65, 78, 68, 69, 68,  1, 71, 76,\n","        79, 66, 65, 76, 76, 89,  1, 65, 78, 68,  1, 87, 65, 83,  1, 82, 85, 78,\n","         1, 65, 84,  1, 77, 85, 76, 84, 73, 80, 76, 69,  1, 76, 79, 67, 65, 84,\n","        73, 79, 78, 83,  1, 65, 82, 79, 85, 78, 68,  1, 84, 72, 69,  1, 87, 79,\n","        82, 76, 68, 15,  1,  1, 41, 79, 87, 69, 86, 69, 82, 13,  1, 65, 70, 84,\n","        69, 82,  1, 34, 80, 80, 76, 69,  1, 80, 85, 82, 67, 72, 65, 83, 69, 68,\n","         1, 77, 69, 84, 65, 73, 79,  1, 73, 78,  1, 46, 65, 89,  1, 19, 17, 18,\n","        22, 13,  1, 77, 69, 84, 65, 73, 79,  1, 67, 65, 78, 67, 69, 76, 76, 69,\n","        68,  1, 84, 72, 69,  1, 42, 78, 83, 73, 68, 69, 34, 51,  1, 67, 79, 78,\n","        70, 69, 82, 69, 78, 67, 69,  1, 19, 17, 18, 22,  1, 87, 73, 84, 72, 79,\n","        85, 84,  1, 65, 78, 89,  1, 83, 84, 65, 84, 69, 77, 69, 78, 84, 83,  1,\n","        65, 66, 79, 85, 84,  1, 84, 72, 69,  1, 67, 79, 78, 70, 69, 82, 69, 78,\n","        67, 69,  8, 83,  1, 70, 85, 84, 85, 82, 69, 15,  1,  0, 53, 72, 69,  1,\n","        39, 69, 65, 82, 73, 78, 71,  1, 46, 73, 78, 68,  1, 73, 83,  1, 65, 78,\n","         1, 34, 77, 69, 82, 73, 67, 65, 78,  1, 72, 79, 82, 82, 79, 82,  1, 84,\n","        69, 76, 69, 86, 73, 83, 73, 79, 78,  1, 83, 69, 82, 73, 69, 83,  1, 84,\n","        72, 65, 84,  1, 65, 73, 82, 69, 68,  1, 79, 78,  1, 84, 72, 69,  1, 39,\n","        79, 88,  1, 39, 65, 77, 73, 76, 89,  1, 36, 72, 65, 78, 78, 69, 76,  1,\n","        70, 82, 79, 77,  1, 48, 67, 84, 79, 66, 69, 82,  1, 19, 18,  1, 85, 78,\n","        84, 73, 76,  1, 37, 69, 67, 69, 77, 66, 69, 82,  1, 19, 13,  1, 19, 17,\n","        17, 17, 15,  1,  0, 35, 73, 76, 76,  1, 39, 69, 65, 82, 73, 78, 71, 13,\n","         1, 65,  1, 70, 65, 77, 79, 85, 83,  1, 87, 82, 73, 84, 69, 82,  1, 79,\n","        70,  1, 83, 85, 83, 80, 69, 78, 83, 69,  1, 84, 72, 82, 73, 76, 76, 69,\n","        82, 83, 13,  1, 71, 69, 84, 83,  1, 72, 73, 83,  1, 73, 68, 69, 65, 83,\n","         1, 70, 82, 79, 77,  1, 84, 72, 73, 78, 71, 83,  1, 84, 72, 65, 84,  1,\n","        72, 65, 80, 80, 69, 78,  1, 73, 78,  1, 72, 73, 83,  1, 70, 65, 77, 73,\n","        76, 89, 15,  1, 56, 72, 69, 78,  1, 72, 69,  1, 71, 69, 84, 83,  1, 65,\n","        78,  1, 73, 68, 69, 65, 13,  1, 84, 72, 69,  1, 86, 73, 69, 87, 69, 82,\n","        83,  1, 69, 78, 84, 69, 82,  1, 72, 73, 83,  1, 77, 73, 78, 68,  1, 65,\n","        78, 68,  1, 83, 69, 69,  1, 84, 72, 69,  1, 71, 82, 85, 69, 83, 79, 77,\n","        69,  1, 69, 86, 69, 78, 84, 83,  1, 85, 78, 70, 79, 76, 68, 15,  1,  0,\n","        42, 84,  1, 72, 65, 68,  1, 65,  1, 66, 82, 79, 78, 90, 69,  1, 66, 65,\n","        82, 82, 69, 76,  1, 65, 78, 68,  1, 76, 65, 67, 75, 69, 68,  1, 65,  1,\n","        77, 79, 68, 69, 82, 78,  1, 82, 69, 67, 79, 73, 76,  1, 83, 89, 83, 84,\n","        69, 77, 13,  1, 85, 83, 73, 78, 71,  1, 79, 78, 76, 89,  1, 65, 78,  1,\n","        73, 78, 69, 70, 70, 69, 67, 84, 73, 86, 69,  1, 83, 80, 82, 73, 78, 71,\n","        14, 77, 79, 85, 78, 84, 69, 68,  1, 83, 80, 65, 68, 69,  1, 66, 82, 65,\n","        75, 69, 13,  1, 65, 78, 68,  1, 87, 65, 83,  1, 86, 73, 82, 84, 85, 65,\n","        76, 76, 89,  1, 79, 66, 83, 79, 76, 69, 83, 67, 69, 78, 84,  1, 79, 78,\n","         1, 73, 84, 83,  1, 73, 78, 84, 82, 79, 68, 85, 67, 84, 73, 79, 78, 15,\n","         1, 47, 79, 78, 69, 84, 72, 69, 76, 69])\n"]}]},{"cell_type":"markdown","source":["TRAINING data set"],"metadata":{"id":"oTX4tuiXI5ho"}},{"cell_type":"code","source":["n=int(0.7*len(data))\n","train_data = data[:n]\n","# val_data = data[n:]"],"metadata":{"id":"J2oenW0II83d","executionInfo":{"status":"ok","timestamp":1730021118755,"user_tz":-330,"elapsed":464,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["context_length=9\n","train_data[:context_length]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pv16ZwrVJpN3","executionInfo":{"status":"ok","timestamp":1730021119984,"user_tz":-330,"elapsed":668,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"d68cd333-44dc-4855-cdb8-1cf08ea8cf15"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([53, 72, 73, 83,  1, 66, 73, 79, 71])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size=5\n","block_size=10\n","\n","def get_batch(split):\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x=torch.stack([data[i:i+block_size] for i in ix])\n","    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    return x,y\n","\n","xb,yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('----')\n","\n","for b in range(batch_size):\n","  for t in range(block_size):\n","    context = xb[b, :t+1]\n","    target = yb[b,t]\n","    print(f\"when input is {context.tolist()} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4u6HZhNSMkC","executionInfo":{"status":"ok","timestamp":1730021161014,"user_tz":-330,"elapsed":415,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"5f750515-d19c-48df-d519-95be50af491c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([5, 10])\n","tensor([[ 1, 72, 69, 76, 68,  1, 65, 84,  1, 84],\n","        [78, 68,  1, 67, 79, 78, 84, 73, 78, 85],\n","        [79, 76, 76, 85, 83, 75,  1, 73, 78,  1],\n","        [77, 65, 78,  1, 84, 79, 76, 68,  1, 43],\n","        [65, 79, 84, 73, 67,  1, 68, 85, 69,  1]])\n","targets:\n","torch.Size([5, 10])\n","tensor([[72, 69, 76, 68,  1, 65, 84,  1, 84, 72],\n","        [68,  1, 67, 79, 78, 84, 73, 78, 85, 69],\n","        [76, 76, 85, 83, 75,  1, 73, 78,  1, 84],\n","        [65, 78,  1, 84, 79, 76, 68,  1, 43, 65],\n","        [79, 84, 73, 67,  1, 68, 85, 69,  1, 84]])\n","----\n","when input is [1] the target: 72\n","when input is [1, 72] the target: 69\n","when input is [1, 72, 69] the target: 76\n","when input is [1, 72, 69, 76] the target: 68\n","when input is [1, 72, 69, 76, 68] the target: 1\n","when input is [1, 72, 69, 76, 68, 1] the target: 65\n","when input is [1, 72, 69, 76, 68, 1, 65] the target: 84\n","when input is [1, 72, 69, 76, 68, 1, 65, 84] the target: 1\n","when input is [1, 72, 69, 76, 68, 1, 65, 84, 1] the target: 84\n","when input is [1, 72, 69, 76, 68, 1, 65, 84, 1, 84] the target: 72\n","when input is [78] the target: 68\n","when input is [78, 68] the target: 1\n","when input is [78, 68, 1] the target: 67\n","when input is [78, 68, 1, 67] the target: 79\n","when input is [78, 68, 1, 67, 79] the target: 78\n","when input is [78, 68, 1, 67, 79, 78] the target: 84\n","when input is [78, 68, 1, 67, 79, 78, 84] the target: 73\n","when input is [78, 68, 1, 67, 79, 78, 84, 73] the target: 78\n","when input is [78, 68, 1, 67, 79, 78, 84, 73, 78] the target: 85\n","when input is [78, 68, 1, 67, 79, 78, 84, 73, 78, 85] the target: 69\n","when input is [79] the target: 76\n","when input is [79, 76] the target: 76\n","when input is [79, 76, 76] the target: 85\n","when input is [79, 76, 76, 85] the target: 83\n","when input is [79, 76, 76, 85, 83] the target: 75\n","when input is [79, 76, 76, 85, 83, 75] the target: 1\n","when input is [79, 76, 76, 85, 83, 75, 1] the target: 73\n","when input is [79, 76, 76, 85, 83, 75, 1, 73] the target: 78\n","when input is [79, 76, 76, 85, 83, 75, 1, 73, 78] the target: 1\n","when input is [79, 76, 76, 85, 83, 75, 1, 73, 78, 1] the target: 84\n","when input is [77] the target: 65\n","when input is [77, 65] the target: 78\n","when input is [77, 65, 78] the target: 1\n","when input is [77, 65, 78, 1] the target: 84\n","when input is [77, 65, 78, 1, 84] the target: 79\n","when input is [77, 65, 78, 1, 84, 79] the target: 76\n","when input is [77, 65, 78, 1, 84, 79, 76] the target: 68\n","when input is [77, 65, 78, 1, 84, 79, 76, 68] the target: 1\n","when input is [77, 65, 78, 1, 84, 79, 76, 68, 1] the target: 43\n","when input is [77, 65, 78, 1, 84, 79, 76, 68, 1, 43] the target: 65\n","when input is [65] the target: 79\n","when input is [65, 79] the target: 84\n","when input is [65, 79, 84] the target: 73\n","when input is [65, 79, 84, 73] the target: 67\n","when input is [65, 79, 84, 73, 67] the target: 1\n","when input is [65, 79, 84, 73, 67, 1] the target: 68\n","when input is [65, 79, 84, 73, 67, 1, 68] the target: 85\n","when input is [65, 79, 84, 73, 67, 1, 68, 85] the target: 69\n","when input is [65, 79, 84, 73, 67, 1, 68, 85, 69] the target: 1\n","when input is [65, 79, 84, 73, 67, 1, 68, 85, 69, 1] the target: 84\n"]}]},{"cell_type":"code","source":["class BigramLanguageModel(nn.Module):\n","\n","  def __init__(self,vocab_size):\n","    super().__init__()\n","    self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n","\n","  def forward(self,index,targets):\n","    logits = self.token_embedding_table(index)\n","    return logits\n","\n","\n","  def generate(self,index,max_new_tokens):\n","    for _ in range(max_new_tokens):\n","      logits = self(index)\n","      logits = logits[:,-1,:]\n","      probs = f.softmax(logits,dim=-1)\n","      index_next = torch.multinomial(probs,num_samples=1)\n","      index = torch.cat((index,index_next),dim=1)\n","\n","      return index\n","m=BigramLanguageModel(vocab_size)\n","out = m(xb,yb)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGqFj3THV1yi","executionInfo":{"status":"ok","timestamp":1730022000732,"user_tz":-330,"elapsed":814,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"81237e9d-b71d-438c-85ab-a5b3cf99da2c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 10, 93])\n"]}]}]}