{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcyoNv0wZd1p4rmU6Nqefk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from IPython import get_ipython\n","from IPython.display import display\n","# %%\n","from tensorflow import math, matmul, reshape, shape, transpose, cast, float32, concat\n","from tensorflow.keras.layers import Dense, Layer\n","from tensorflow.keras.backend import softmax\n","# Implementing the Scaled-Dot Product Attention\n","\n","class DotProductAttention(Layer):\n","  def __init__(self, **kwargs):\n","    super().__init__(**kwargs)\n","\n","  def call(self, queries, keys, values, mask=None):\n","    d_k = queries.shape[-1]\n","    # Scoring the queries against the keys after transposing the latter, and scaling\n","    scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n","    # Apply mask to the attention scores\n","    if mask is not None:\n","      scores += -1e9 * mask\n","    # Computing the weights by a softmax operation\n","    weights = softmax(scores)\n","    # Computing the attention by a weighted sum of the value vectors\n","    return matmul(weights, values)\n","    # Implementing the Multi-Head Attention\n","\n","class MultiHeadAttention(Layer):\n","  def __init__(self, h, d_k, d_v, d_model, **kwargs):\n","    super().__init__(**kwargs)\n","    self.attention = DotProductAttention() # Scaled dot product attention\n","    self.heads = h # Number of attention heads to use\n","    self.d_k = d_k # Dimensionality of the linearly projected queries and keys\n","    self.d_v = d_v # Dimensionality of the linearly projected values\n","    self.d_model = d_model # Dimensionality of the model\n","    self.W_q = Dense(d_k) # Learned projection matrix for the queries\n","    self.W_k = Dense(d_k) # Learned projection matrix for the keys\n","    self.W_v = Dense(d_v) # Learned projection matrix for the values\n","    self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n","\n","  def reshape_tensor(self, x, heads, flag):\n","    if flag:\n","      # Tensor shape after reshaping and transposing:\n","      # (batch_size, heads, seq_length, -1)\n","      x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n","      x = transpose(x, perm=(0, 2, 1, 3))\n","    else:\n","        x = transpose(x, perm=(0, 2, 1, 3))\n","        x_shape = shape(x)\n","        new_shape = (x_shape[0], x_shape[1], x_shape[2] * x_shape[3])\n","        x = reshape(x, new_shape)\n","\n","    return x\n","\n","  def call(self, queries, keys, values, mask=None):\n","    # Rearrange the queries to be able to compute all heads in parallel\n","    q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n","    # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n","    # Rearrange the keys to be able to compute all heads in parallel\n","    k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n","    # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n","    # Rearrange the values to be able to compute all heads in parallel\n","    v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n","    # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n","    # Compute the multi-head attention output using the reshaped queries,\n","    # keys, and values\n","    o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, mask=mask)\n","    # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n","    # Rearrange back the output into concatenated form\n","    output = self.reshape_tensor(o_reshaped, self.heads, False)\n","    # Resulting tensor shape: (batch_size, input_seq_length, d_model)\n","    return self.W_o(output)\n","# %%\n","from numpy import random\n","input_seq_length = 5 # Maximum length of the input sequence\n","h = 8 # Number of self-attention heads\n","d_k = 64 # Dimensionality of the linearly projected queries and keys\n","d_v = 64 # Dimensionality of the linearly projected values\n","d_model = 512 # Dimensionality of the model sub-layers' outputs\n","batch_size = 64 # Batch size from the training process\n","queries = random.random((batch_size, input_seq_length, d_k))\n","keys = random.random((batch_size, input_seq_length, d_k))\n","values = random.random((batch_size, input_seq_length, d_v))\n","multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n","print(multihead_attention(queries, keys, values))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uC-EDMRG8EUj","executionInfo":{"status":"ok","timestamp":1736239502825,"user_tz":-330,"elapsed":1439,"user":{"displayName":"ARAVINDH","userId":"17493391128659897074"}},"outputId":"bf874138-c6d7-4b3f-89ed-46bd2d7014f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[ 0.14855118  0.20013703 -0.02880823 ...  0.01359212 -0.44502118\n","    0.06768567]\n","  [ 0.13617986  0.19600089 -0.02540962 ...  0.02122036 -0.43507555\n","    0.06835034]\n","  [ 0.13912079  0.20453653 -0.02111277 ...  0.01619427 -0.4403253\n","    0.07720984]\n","  [ 0.13880375  0.20353049 -0.02084962 ...  0.01248611 -0.4367996\n","    0.0766429 ]\n","  [ 0.1421045   0.19639619 -0.02397741 ...  0.01725038 -0.44577417\n","    0.07329702]]\n","\n"," [[ 0.28757727  0.09672768 -0.04910994 ...  0.15489005 -0.63113034\n","    0.19256432]\n","  [ 0.29114443  0.08817305 -0.03802683 ...  0.15269296 -0.63121635\n","    0.19065249]\n","  [ 0.29930386  0.09466944 -0.04478071 ...  0.14228976 -0.6378579\n","    0.20184374]\n","  [ 0.29785025  0.09283872 -0.04667297 ...  0.14812633 -0.6405736\n","    0.19957878]\n","  [ 0.2941439   0.0961503  -0.04171791 ...  0.15648103 -0.6281992\n","    0.1887621 ]]\n","\n"," [[ 0.27810428  0.39767057 -0.03655063 ... -0.1052499  -0.5261304\n","    0.06247696]\n","  [ 0.28281605  0.39534903 -0.044312   ... -0.09199257 -0.51383215\n","    0.06096466]\n","  [ 0.27804074  0.38211682 -0.04314008 ... -0.09714787 -0.51543736\n","    0.06253705]\n","  [ 0.27619138  0.39521244 -0.03985411 ... -0.09966075 -0.5319189\n","    0.0522769 ]\n","  [ 0.27649269  0.39325    -0.04326569 ... -0.10259094 -0.5266491\n","    0.05885518]]\n","\n"," ...\n","\n"," [[ 0.29811716  0.22968967 -0.0191356  ...  0.05191146 -0.38873747\n","    0.14449164]\n","  [ 0.2840387   0.22293232 -0.03547596 ...  0.0578072  -0.39164075\n","    0.15467055]\n","  [ 0.29504237  0.21653986 -0.03236219 ...  0.06100021 -0.39021713\n","    0.1564761 ]\n","  [ 0.28780314  0.23071994 -0.02994904 ...  0.06212546 -0.3909986\n","    0.14733079]\n","  [ 0.28654888  0.22665401 -0.03285592 ...  0.04983267 -0.39273244\n","    0.14557065]]\n","\n"," [[ 0.24909857  0.10241992 -0.03670557 ...  0.05312049 -0.34615016\n","    0.08081946]\n","  [ 0.2621144   0.1014227  -0.03958398 ...  0.05678897 -0.35305476\n","    0.09205507]\n","  [ 0.25042376  0.10251962 -0.04087262 ...  0.06512529 -0.34684587\n","    0.0860672 ]\n","  [ 0.25297365  0.10156456 -0.03439382 ...  0.05318771 -0.3429858\n","    0.08078207]\n","  [ 0.25451583  0.10322758 -0.03853434 ...  0.05949031 -0.34815076\n","    0.09558949]]\n","\n"," [[ 0.27113485  0.2663768  -0.06738104 ... -0.1190083  -0.48508057\n","    0.07692834]\n","  [ 0.26882175  0.2763594  -0.07312302 ... -0.1258573  -0.49550542\n","    0.08796884]\n","  [ 0.2699388   0.26579902 -0.07037514 ... -0.12411688 -0.48398468\n","    0.0814463 ]\n","  [ 0.26470453  0.26571622 -0.07248258 ... -0.12013637 -0.4887588\n","    0.07625381]\n","  [ 0.27321693  0.27292132 -0.06984836 ... -0.12492561 -0.4923152\n","    0.08658706]]], shape=(64, 5, 512), dtype=float32)\n"]}]}]}