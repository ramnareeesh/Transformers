{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:47.373985Z",
     "start_time": "2025-01-07T08:30:47.371804Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout,TextVectorization, Embedding\n",
    "# from keras.backend import softmax \n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:39:04.179013Z",
     "start_time": "2025-01-07T08:39:04.164345Z"
    }
   },
   "cell_type": "code",
   "source": "tf.__version__",
   "id": "f57e2ea5d1c4df2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:38:12.546842Z",
     "start_time": "2025-01-07T08:38:12.543668Z"
    }
   },
   "cell_type": "code",
   "source": "tf.keras.__version__",
   "id": "f1bf6e30de02989",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "c8eedbd527817ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Positional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d541c35d3d8ae5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:48.616224Z",
     "start_time": "2025-01-07T08:30:48.612910Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PositionEmbeddingFixedWeights(Layer):\n",
    "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
    "        pos_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
    "        self.word_embedding_layer = Embedding(input_dim=vocab_size, output_dim=output_dim,weights=[word_embedding_matrix],trainable=False)\n",
    "        self.position_embedding_layer = Embedding(input_dim=seq_length, output_dim=output_dim,weights=[pos_embedding_matrix],trainable=False)\n",
    "    \n",
    "    def get_position_encoding(self, seq_len, d, n=10000):\n",
    "        P = np.zeros((seq_len, d))\n",
    "        for k in range(seq_len):\n",
    "            for i in np.arange(int(d/2)):\n",
    "                denominator = np.power(n, 2*i/d)\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return P\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb726f4448ab0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single headed Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70074e3fcc0f604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:49.825106Z",
     "start_time": "2025-01-07T08:30:49.822724Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DotProductAttention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self,queries,keys,values,d_k,mask = None):\n",
    "        \n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "        \n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "        \n",
    "        # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "        \n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return matmul(weights, values)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c0f68500a54a6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Multi - headed self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509bfc0c5150ec2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:50.226389Z",
     "start_time": "2025-01-07T08:30:50.222673Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention() # Scaled dot product attention\n",
    "        self.heads = h # Number of attention heads to use\n",
    "        self.d_k = d_k # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v # Dimensionality of the linearly projected values\n",
    "        self.d_model = d_model # Dimensionality of the model\n",
    "        self.W_q = Dense(d_k) # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k) # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v) # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            # Tensor shape after reshaping and transposing:\n",
    "            # (batch_size, heads, seq_length, -1)\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            # Reverting the reshaping and transposing operations:\n",
    "            # (batch_size, seq_length, d_k)\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
    "        return x\n",
    "    \n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        # Rearrange the queries to be able to compute all heads in parallel\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "        # Rearrange the keys to be able to compute all heads in parallel\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "        # Rearrange the values to be able to compute all heads in parallel\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "        # Compute the multi-head attention output using the reshaped queries,\n",
    "        # keys, and values\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "        # Rearrange back the output into concatenated form\n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
    "        # Apply one final linear projection to the output to generate the multi-head\n",
    "        # attention. Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfcd918e2ea99af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e21c6cd2173a129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:50.574643Z",
     "start_time": "2025-01-07T08:30:50.572182Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implementing the Add & Norm Layer\n",
    "class AddNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer_norm = LayerNormalization() # Layer normalization layer\n",
    "    def call(self, x, sublayer_x):\n",
    "        # The sublayer input and output need to be of the same shape to be summed\n",
    "        add = x + sublayer_x\n",
    "        # Apply layer normalization to the sum\n",
    "        return self.layer_norm(add)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55755539e20295e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feed forward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d656aceea94273d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:50.983733Z",
     "start_time": "2025-01-07T08:30:50.980332Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implementing the Feed-Forward Layer\n",
    "class FeedForward(Layer):\n",
    "    def __init__(self, d_ff, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fully_connected1 = Dense(d_ff) # First fully connected layer\n",
    "        self.fully_connected2 = Dense(d_model) # Second fully connected layer\n",
    "        self.activation = ReLU() # ReLU activation layer\n",
    "        \n",
    "    def call(self, x):\n",
    "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
    "        x_fc1 = self.fully_connected1(x)\n",
    "        return self.fully_connected2(self.activation(x_fc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ea7129f25aaa3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### A single decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b155ac7fc3e94d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:30:51.541759Z",
     "start_time": "2025-01-07T08:30:51.538276Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "        self.add_norm3 = AddNormalization()\n",
    "    \n",
    "    \n",
    "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n",
    "         \n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        # Add in a dropout layer\n",
    "        multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output1 = self.add_norm1(x, multihead_output1)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        # Followed by another multi-head attention layer\n",
    "        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output,encoder_output, padding_mask)\n",
    "         \n",
    "        # Add in another dropout layer\n",
    "        multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
    "        \n",
    "        # Followed by another Add & Norm layer\n",
    "        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n",
    "        \n",
    "        # Followed by a fully connected layer\n",
    "        feedforward_output = self.feed_forward(addnorm_output2)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout3(feedforward_output, training=training)\n",
    "        \n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm3(addnorm_output2, feedforward_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34dcaf58a81a352",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Decoder construct"
   ]
  },
  {
   "cell_type": "code",
   "id": "1042d92555ff92ff",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T09:21:49.478576Z",
     "start_time": "2025-01-07T09:21:49.475263Z"
    }
   },
   "source": [
    "class Decoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
    "        \n",
    "    \n",
    "    def call(self, output_target, encoder_output, lookahead_mask=None, padding_mask=None, training=False):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(output_target)\n",
    "        # Expected output shape = (number of sentences, sequence_length, d_model)\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.decoder_layer):\n",
    "            x = layer(x, encoder_output, lookahead_mask=lookahead_mask, padding_mask=padding_mask, training=training)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "6aeed9fdb72b3bf8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T08:39:59.891439Z",
     "start_time": "2025-01-07T08:39:59.888369Z"
    }
   },
   "source": [
    "h = 8 # Number of self-attention heads\n",
    "d_k = 64 # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64 # Dimensionality of the linearly projected values\n",
    "d_ff = 2048 # Dimensionality of the inner fully connected layer\n",
    "d_model = 512 # Dimensionality of the model sub-layers' outputs\n",
    "n = 6 # Number of layers in the encoder stack\n",
    "batch_size = 64 # Batch size from the training process\n",
    "dropout_rate = 0.1 # Frequency of dropping the input units in the dropout layers"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "bd7ade4077f7665b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T08:40:00.127940Z",
     "start_time": "2025-01-07T08:40:00.123387Z"
    }
   },
   "source": [
    "dec_vocab_size = 20 # Vocabulary size for the decoder\n",
    "input_seq_length = 5 # Maximum length of the input sequence\n",
    "input_seq = np.random.rand(batch_size, input_seq_length)\n",
    "enc_output = np.random.rand(batch_size, input_seq_length, d_model)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "7475e17b5afc0035",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T08:40:00.436662Z",
     "start_time": "2025-01-07T08:40:00.432085Z"
    }
   },
   "source": [
    "input_seq"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85404104, 0.6590931 , 0.00801142, 0.15239133, 0.90819242],\n",
       "       [0.57147685, 0.87189948, 0.46574859, 0.95172972, 0.16893189],\n",
       "       [0.8370025 , 0.87666555, 0.83163383, 0.51620282, 0.21303305],\n",
       "       [0.32213007, 0.48830044, 0.02404684, 0.44876341, 0.96598851],\n",
       "       [0.14453682, 0.31114745, 0.13151907, 0.54885457, 0.62306043],\n",
       "       [0.06882451, 0.95322895, 0.28961088, 0.36076364, 0.60142198],\n",
       "       [0.03123791, 0.23143449, 0.60407628, 0.37560397, 0.5530125 ],\n",
       "       [0.08261558, 0.95814627, 0.02462276, 0.1219724 , 0.17036007],\n",
       "       [0.65737732, 0.8539066 , 0.32106262, 0.14379717, 0.75005263],\n",
       "       [0.86897311, 0.02070043, 0.10383817, 0.00396981, 0.95984319],\n",
       "       [0.17923014, 0.909579  , 0.38651565, 0.05013358, 0.8992825 ],\n",
       "       [0.51917468, 0.70918715, 0.10842953, 0.36571321, 0.63359847],\n",
       "       [0.63852509, 0.69150957, 0.75571145, 0.55296803, 0.23657143],\n",
       "       [0.01434756, 0.06438124, 0.62329489, 0.92799422, 0.16680802],\n",
       "       [0.56505058, 0.14176671, 0.33911722, 0.89896331, 0.24807086],\n",
       "       [0.25982637, 0.90108176, 0.38771216, 0.690771  , 0.94496861],\n",
       "       [0.34832578, 0.07096906, 0.82730057, 0.37407384, 0.74246462],\n",
       "       [0.26242737, 0.10559905, 0.79707945, 0.63130029, 0.83657374],\n",
       "       [0.21136316, 0.52896932, 0.64007656, 0.62755847, 0.52231859],\n",
       "       [0.25536176, 0.58450687, 0.33939666, 0.8747657 , 0.92954708],\n",
       "       [0.74085808, 0.83076431, 0.0152162 , 0.95528081, 0.72635813],\n",
       "       [0.27120339, 0.39708266, 0.57319202, 0.97310615, 0.77654722],\n",
       "       [0.64622279, 0.49152058, 0.65234858, 0.56956851, 0.40520515],\n",
       "       [0.39645903, 0.74043224, 0.33016989, 0.10872519, 0.23441651],\n",
       "       [0.12895648, 0.21972509, 0.28098405, 0.10608077, 0.57731869],\n",
       "       [0.22285932, 0.3142263 , 0.50648161, 0.90541193, 0.27347294],\n",
       "       [0.13784034, 0.82575146, 0.66687813, 0.00456224, 0.76764706],\n",
       "       [0.74756076, 0.16510936, 0.58615898, 0.8335379 , 0.59809549],\n",
       "       [0.94641394, 0.57451007, 0.10679791, 0.49225929, 0.86468223],\n",
       "       [0.35381624, 0.49100018, 0.6976525 , 0.39098738, 0.80369557],\n",
       "       [0.62785963, 0.81070006, 0.2179362 , 0.48427251, 0.82970071],\n",
       "       [0.77749133, 0.63478973, 0.41995408, 0.61837018, 0.45752679],\n",
       "       [0.07575435, 0.1225782 , 0.45249274, 0.37051024, 0.10957146],\n",
       "       [0.07152492, 0.82883516, 0.80661124, 0.8885472 , 0.68748032],\n",
       "       [0.77388186, 0.91571078, 0.95959269, 0.13117693, 0.72076288],\n",
       "       [0.01550439, 0.18595437, 0.63862894, 0.69923158, 0.94221675],\n",
       "       [0.30728272, 0.25991537, 0.54340867, 0.10836725, 0.96864804],\n",
       "       [0.35090022, 0.95650933, 0.69172268, 0.9548158 , 0.49015167],\n",
       "       [0.34793752, 0.64802368, 0.66090549, 0.42272925, 0.21298183],\n",
       "       [0.03781157, 0.1706453 , 0.23908846, 0.75570326, 0.90808022],\n",
       "       [0.36486787, 0.03608314, 0.71138684, 0.11123311, 0.24199036],\n",
       "       [0.13637385, 0.33907236, 0.89314952, 0.42061799, 0.553824  ],\n",
       "       [0.32966718, 0.71146613, 0.71499318, 0.00264421, 0.05348966],\n",
       "       [0.00782474, 0.0338418 , 0.05943261, 0.40654128, 0.0681517 ],\n",
       "       [0.43005242, 0.60435387, 0.08518581, 0.1073212 , 0.35641457],\n",
       "       [0.71537343, 0.41979336, 0.35743181, 0.29848342, 0.95012128],\n",
       "       [0.70746141, 0.76927836, 0.11807521, 0.01890038, 0.36993737],\n",
       "       [0.26693775, 0.04784481, 0.65100673, 0.05853663, 0.24429204],\n",
       "       [0.14834925, 0.01678198, 0.27700172, 0.38220558, 0.83901548],\n",
       "       [0.42507146, 0.55502826, 0.53376448, 0.76459468, 0.15651035],\n",
       "       [0.70138006, 0.61271873, 0.8916298 , 0.66273417, 0.87198095],\n",
       "       [0.80833969, 0.74600214, 0.37658616, 0.6993698 , 0.20798515],\n",
       "       [0.90476204, 0.42482964, 0.84294919, 0.56408101, 0.66267946],\n",
       "       [0.30239745, 0.80090188, 0.38108574, 0.96884106, 0.15707191],\n",
       "       [0.70573992, 0.99696238, 0.70918272, 0.24678666, 0.76949949],\n",
       "       [0.79415574, 0.41939857, 0.46310613, 0.17354232, 0.11561976],\n",
       "       [0.6265061 , 0.54479447, 0.77496045, 0.4908676 , 0.93077851],\n",
       "       [0.30019328, 0.66264512, 0.9849256 , 0.01506461, 0.44894235],\n",
       "       [0.55986444, 0.05580941, 0.45974126, 0.87607311, 0.00913599],\n",
       "       [0.46952831, 0.05714846, 0.04183081, 0.40144746, 0.29988306],\n",
       "       [0.35420035, 0.80857503, 0.41150688, 0.95031417, 0.72819597],\n",
       "       [0.60451113, 0.9194092 , 0.22457197, 0.98185609, 0.66380944],\n",
       "       [0.37114535, 0.37233534, 0.40699431, 0.85832512, 0.93663882],\n",
       "       [0.69795441, 0.41010319, 0.57422072, 0.19454359, 0.49447961]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "1cb5486f2d723270",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T08:40:00.978016Z",
     "start_time": "2025-01-07T08:40:00.975886Z"
    }
   },
   "source": [
    "enc_output.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "097bf2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:40:01.777881Z",
     "start_time": "2025-01-07T08:40:01.774643Z"
    }
   },
   "source": [
    "print(\"Input Sequence Shape:\", input_seq.shape)\n",
    "print(\"Encoder Output Shape:\", enc_output.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence Shape: (64, 5)\n",
      "Encoder Output Shape: (64, 5, 512)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "7eb2ce593ae43fb8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T09:21:56.161041Z",
     "start_time": "2025-01-07T09:21:55.718884Z"
    }
   },
   "source": [
    "decoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "res = decoder(input_seq, enc_output, lookahead_mask=None, padding_mask=None, training=True)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling MultiHeadAttention.call().\n\n\u001B[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: 64 (of type <class 'int'>)\u001B[0m\n\nArguments received by MultiHeadAttention.call():\n  • queries=tf.Tensor(shape=(64, 5, 512), dtype=float32)\n  • keys=tf.Tensor(shape=(64, 5, 512), dtype=float32)\n  • values=tf.Tensor(shape=(64, 5, 512), dtype=float32)\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m decoder \u001B[38;5;241m=\u001B[39m Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n\u001B[0;32m----> 2\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menc_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookahead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Transformers/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[0;32mIn[38], line 17\u001B[0m, in \u001B[0;36mDecoder.call\u001B[0;34m(self, output_target, encoder_output, lookahead_mask, padding_mask, training)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Pass on the positional encoded values to each encoder layer\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_layer):\n\u001B[0;32m---> 17\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookahead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlookahead_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "Cell \u001B[0;32mIn[9], line 17\u001B[0m, in \u001B[0;36mDecoderLayer.call\u001B[0;34m(self, x, encoder_output, lookahead_mask, padding_mask, training)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, encoder_output, lookahead_mask, padding_mask, training):\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# Multi-head attention layer\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m     multihead_output1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultihead_attention1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookahead_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# Expected output shape = (batch_size, sequence_length, d_model)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m# Add in a dropout layer\u001B[39;00m\n\u001B[1;32m     21\u001B[0m     multihead_output1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(multihead_output1, training\u001B[38;5;241m=\u001B[39mtraining)\n",
      "Cell \u001B[0;32mIn[6], line 38\u001B[0m, in \u001B[0;36mMultiHeadAttention.call\u001B[0;34m(self, queries, keys, values, mask)\u001B[0m\n\u001B[1;32m     34\u001B[0m v_reshaped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreshape_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_v(values), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Compute the multi-head attention output using the reshaped queries,\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# keys, and values\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m o_reshaped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_k\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Rearrange back the output into concatenated form\u001B[39;00m\n\u001B[1;32m     41\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreshape_tensor(o_reshaped, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling MultiHeadAttention.call().\n\n\u001B[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: 64 (of type <class 'int'>)\u001B[0m\n\nArguments received by MultiHeadAttention.call():\n  • queries=tf.Tensor(shape=(64, 5, 512), dtype=float32)\n  • keys=tf.Tensor(shape=(64, 5, 512), dtype=float32)\n  • values=tf.Tensor(shape=(64, 5, 512), dtype=float32)\n  • mask=None"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c0786747a8cdf51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T08:31:03.997008Z",
     "start_time": "2025-01-07T08:31:03.983277Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mres\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mNameError\u001B[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ed8d4a6bd11171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T18:35:07.316348Z",
     "start_time": "2025-01-05T18:35:07.290869Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 5, 512), dtype=float32, numpy=\n",
       "array([[[-1.0012507 , -0.02040063,  0.00654149, ...,  0.00182297,\n",
       "         -0.42907837, -0.6750074 ],\n",
       "        [-0.9141136 , -0.07876357,  0.03269473, ...,  0.02028901,\n",
       "         -0.41397125, -0.6715221 ],\n",
       "        [-0.8649395 , -0.19943327,  0.00265713, ...,  0.04040005,\n",
       "         -0.37729064, -0.67488515],\n",
       "        [-0.9230531 , -0.2717329 , -0.06383975, ...,  0.04616989,\n",
       "         -0.34594226, -0.6787786 ],\n",
       "        [-1.0300083 , -0.24937628, -0.1109768 , ...,  0.03863088,\n",
       "         -0.34787044, -0.66987866]],\n",
       "\n",
       "       [[-1.134145  , -0.16023272, -0.10939384, ...,  0.03158534,\n",
       "         -0.41963074, -0.65775114],\n",
       "        [-1.0422376 , -0.21190177, -0.07916868, ...,  0.04733095,\n",
       "         -0.41154853, -0.655486  ],\n",
       "        [-1.0103201 , -0.32608616, -0.1004246 , ...,  0.04688325,\n",
       "         -0.3615602 , -0.65161943],\n",
       "        [-1.0573205 , -0.38737077, -0.1575223 , ...,  0.03170759,\n",
       "         -0.31814742, -0.65505326],\n",
       "        [-1.1520594 , -0.34790927, -0.18702297, ...,  0.03047681,\n",
       "         -0.3235996 , -0.65976095]],\n",
       "\n",
       "       [[-0.6734646 , -0.14057362, -0.0423853 , ...,  0.21616137,\n",
       "         -0.5318386 , -0.937553  ],\n",
       "        [-0.59559214, -0.19526497, -0.00151302, ...,  0.22385319,\n",
       "         -0.5160938 , -0.9401504 ],\n",
       "        [-0.5666309 , -0.3097906 , -0.01718177, ...,  0.2314818 ,\n",
       "         -0.47569776, -0.9396242 ],\n",
       "        [-0.6188326 , -0.37868732, -0.0776031 , ...,  0.23309459,\n",
       "         -0.42352363, -0.9451476 ],\n",
       "        [-0.703842  , -0.33201718, -0.10975006, ...,  0.22397089,\n",
       "         -0.4288697 , -0.9407465 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.8211654 , -0.05113678, -0.26725218, ...,  0.04656707,\n",
       "         -0.4503048 , -0.9376925 ],\n",
       "        [-0.7317867 , -0.11553456, -0.23223436, ...,  0.0532905 ,\n",
       "         -0.41821334, -0.933482  ],\n",
       "        [-0.6828832 , -0.2358656 , -0.24893692, ...,  0.05457299,\n",
       "         -0.35571402, -0.9246599 ],\n",
       "        [-0.7348195 , -0.30671126, -0.31394383, ...,  0.06690654,\n",
       "         -0.30722928, -0.92912275],\n",
       "        [-0.8381103 , -0.2899763 , -0.3647644 , ...,  0.05792283,\n",
       "         -0.30422267, -0.94235945]],\n",
       "\n",
       "       [[-1.0343877 ,  0.03896032, -0.22665223, ..., -0.01582331,\n",
       "         -0.53316545, -0.66323805],\n",
       "        [-0.95466304, -0.02256884, -0.18402317, ..., -0.0037193 ,\n",
       "         -0.50158745, -0.6671755 ],\n",
       "        [-0.9177791 , -0.13686404, -0.198793  , ..., -0.00505069,\n",
       "         -0.4453437 , -0.66205895],\n",
       "        [-0.9545235 , -0.20158617, -0.25848526, ..., -0.0194883 ,\n",
       "         -0.40419042, -0.6586941 ],\n",
       "        [-1.0396827 , -0.17862612, -0.28884673, ..., -0.02621641,\n",
       "         -0.42142886, -0.66045713]],\n",
       "\n",
       "       [[-0.7672183 , -0.0120923 , -0.3131236 , ..., -0.29756242,\n",
       "         -0.38502547, -0.6271683 ],\n",
       "        [-0.67012775, -0.0831218 , -0.2746861 , ..., -0.28572404,\n",
       "         -0.37515998, -0.6265607 ],\n",
       "        [-0.6323371 , -0.21177515, -0.29679585, ..., -0.2792723 ,\n",
       "         -0.32841775, -0.6250044 ],\n",
       "        [-0.6832223 , -0.28658298, -0.35914865, ..., -0.27369967,\n",
       "         -0.28226262, -0.6386333 ],\n",
       "        [-0.785123  , -0.2561357 , -0.38707802, ..., -0.28426933,\n",
       "         -0.28726724, -0.6563299 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede4c1e90269b36",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
